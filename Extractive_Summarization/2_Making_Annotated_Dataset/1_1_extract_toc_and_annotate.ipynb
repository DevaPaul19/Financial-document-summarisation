{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from extract_toc import extract_toc\n",
    "from annotate_toc import annotate_toc_against_sumamry, annotate_toc_for_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/training/'\n",
    "valid_dir = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/'\n",
    "test_dir = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/testing/'\n",
    "out = 'out'\n",
    "annual_reports_dir = \"annual_reports\"\n",
    "gold_summary_dir = \"gold_summaries\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'train_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'train_toc_len.pkl'\n",
    "out_dir_path = os.path.join(train_dir, out)\n",
    "out_annotated_file_name = 'train_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3050\n",
      "Processing File Number:  0\n",
      "Processing File Number:  300\n",
      "TOC not found in:  13349.txt\n",
      "Processing File Number:  600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\My folders\\Deva paul\\AI\\SEM 5\\356 NLP\\NLP Project\\New folder\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 554, in extract_toc\n",
      "    if abs(start_pos - pages[0]) > 100:\n",
      "IndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOC not found in:  16836.txt\n",
      "TOC not found in:  16837.txt\n",
      "Processing File Number:  900\n",
      "TOC not found in:  18615.txt\n",
      "Processing File Number:  1200\n",
      "Processing File Number:  1500\n",
      "Processing File Number:  1800\n",
      "TOC not found in:  4062.txt\n",
      "Processing File Number:  2100\n",
      "Processing File Number:  2400\n",
      "TOC not found in:  7386.txt\n",
      "Processing File Number:  2700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\My folders\\Deva paul\\AI\\SEM 5\\356 NLP\\NLP Project\\New folder\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 552, in extract_toc\n",
      "    pages = weak_search(toc, pages_search_by_title, tmp_file)\n",
      "TypeError: weak_search() missing 1 required positional argument: 'start_pos'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\My folders\\Deva paul\\AI\\SEM 5\\356 NLP\\NLP Project\\New folder\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 552, in extract_toc\n",
      "    pages = weak_search(toc, pages_search_by_title, tmp_file)\n",
      "TypeError: weak_search() missing 1 required positional argument: 'start_pos'\n"
     ]
    }
   ],
   "source": [
    "file_toc_loc, file_toc_len = extract_toc(train_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/training/out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21216\\648227321.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_toc_pos_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout_pickle_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_toc_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_pickle_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/training/out'"
     ]
    }
   ],
   "source": [
    "os.mkdir(out_dir_path)\n",
    "\n",
    "with open(os.path.join(out_dir_path, out_toc_pos_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(file_toc_loc, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(out_dir_path, out_toc_len_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(file_toc_len, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_toc_loc.pkl  loaded\n",
      "train_toc_len.pkl  loaded\n",
      "Total sections to be processed:  68901\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  300\n",
      "processing file num  600\n",
      "processing file num  900\n",
      "processing file num  1200\n",
      "processing file num  1500\n",
      "processing file num  1800\n",
      "processing file num  2100\n",
      "processing file num  2400\n",
      "processing file num  2700\n",
      "processing file num  3000\n",
      "Annotated dataset shape (68901, 5)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = annotate_toc_against_sumamry(train_dir, gold_summary_dir, os.path.join(train_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>toc_section</th>\n",
       "      <th>toc_section_pos</th>\n",
       "      <th>toc_section_len</th>\n",
       "      <th>is_section_in_summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10023</td>\n",
       "      <td>Highlights</td>\n",
       "      <td>37</td>\n",
       "      <td>60</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10023</td>\n",
       "      <td>The Company at a glance</td>\n",
       "      <td>97</td>\n",
       "      <td>88</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10023</td>\n",
       "      <td>Our strategy for growth</td>\n",
       "      <td>185</td>\n",
       "      <td>37</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10023</td>\n",
       "      <td>Chairman’s statement</td>\n",
       "      <td>222</td>\n",
       "      <td>160</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10023</td>\n",
       "      <td>Chief Executive’s report</td>\n",
       "      <td>382</td>\n",
       "      <td>187</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10023</td>\n",
       "      <td>Financial review</td>\n",
       "      <td>569</td>\n",
       "      <td>774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10023</td>\n",
       "      <td>Principal risks and uncertainties</td>\n",
       "      <td>1343</td>\n",
       "      <td>166</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10023</td>\n",
       "      <td>Board of Directors</td>\n",
       "      <td>1509</td>\n",
       "      <td>154</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10023</td>\n",
       "      <td>Senior management</td>\n",
       "      <td>1663</td>\n",
       "      <td>117</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10023</td>\n",
       "      <td>Directors’ report</td>\n",
       "      <td>1780</td>\n",
       "      <td>220</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10023</td>\n",
       "      <td>Corporate governance statement</td>\n",
       "      <td>2000</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10023</td>\n",
       "      <td>Remuneration report</td>\n",
       "      <td>2085</td>\n",
       "      <td>73</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10023</td>\n",
       "      <td>Independent auditors’ report</td>\n",
       "      <td>2158</td>\n",
       "      <td>119</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10023</td>\n",
       "      <td>Financial statements</td>\n",
       "      <td>2277</td>\n",
       "      <td>1732</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10023</td>\n",
       "      <td>Notice of Annual General Meeting</td>\n",
       "      <td>4009</td>\n",
       "      <td>239</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10023</td>\n",
       "      <td>Corporate directory</td>\n",
       "      <td>4248</td>\n",
       "      <td>101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file_id                        toc_section  toc_section_pos  \\\n",
       "0    10023                         Highlights               37   \n",
       "1    10023            The Company at a glance               97   \n",
       "2    10023            Our strategy for growth              185   \n",
       "3    10023               Chairman’s statement              222   \n",
       "4    10023           Chief Executive’s report              382   \n",
       "5    10023                   Financial review              569   \n",
       "6    10023  Principal risks and uncertainties             1343   \n",
       "7    10023                 Board of Directors             1509   \n",
       "8    10023                  Senior management             1663   \n",
       "9    10023                  Directors’ report             1780   \n",
       "10   10023     Corporate governance statement             2000   \n",
       "11   10023                Remuneration report             2085   \n",
       "12   10023       Independent auditors’ report             2158   \n",
       "13   10023               Financial statements             2277   \n",
       "14   10023   Notice of Annual General Meeting             4009   \n",
       "15   10023                Corporate directory             4248   \n",
       "\n",
       "    toc_section_len  is_section_in_summary  \n",
       "0                60                   True  \n",
       "1                88                   True  \n",
       "2                37                  False  \n",
       "3               160                   True  \n",
       "4               187                   True  \n",
       "5               774                  False  \n",
       "6               166                  False  \n",
       "7               154                  False  \n",
       "8               117                  False  \n",
       "9               220                  False  \n",
       "10               85                  False  \n",
       "11               73                  False  \n",
       "12              119                  False  \n",
       "13             1732                  False  \n",
       "14              239                  False  \n",
       "15              101                  False  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_annotated_df[toc_annotated_df['file_id']=='10023']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24344    56\n",
       "20810    50\n",
       "13986    49\n",
       "17777    47\n",
       "19669    47\n",
       "         ..\n",
       "14008     6\n",
       "9246      6\n",
       "5895      6\n",
       "4476      4\n",
       "6132      1\n",
       "Name: file_id, Length: 3030, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toc_annotated_df['file_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'valid_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'valid_toc_len.pkl'\n",
    "out_dir_path = os.path.join(valid_dir, out)\n",
    "out_annotated_file_name = 'valid_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "413\n",
      "Processing File Number:  0\n",
      "Processing File Number:  300\n"
     ]
    }
   ],
   "source": [
    "valid_file_toc_loc, valid_file_toc_len = extract_toc(valid_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/out'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21216\\3642677117.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_dir_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_toc_pos_file_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mout_pickle_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalid_file_toc_loc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_pickle_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mHIGHEST_PROTOCOL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/out'"
     ]
    }
   ],
   "source": [
    "os.mkdir(out_dir_path)\n",
    "\n",
    "with open(os.path.join(out_dir_path, out_toc_pos_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(valid_file_toc_loc, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(out_dir_path, out_toc_len_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(valid_file_toc_len, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid_toc_loc.pkl  loaded\n",
      "valid_toc_len.pkl  loaded\n",
      "Total sections to be processed:  10552\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  300\n",
      "Annotated dataset shape (10552, 5)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = at.annotate_toc_against_sumamry(valid_dir, gold_summary_dir, os.path.join(valid_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract TOC in Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_toc_pos_file_name = 'test_toc_loc.pkl'\n",
    "out_toc_len_file_name = 'test_toc_len.pkl'\n",
    "out_dir_path = os.path.join(test_dir, out)\n",
    "out_annotated_file_name = 'test_annotated.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550\n",
      "Processing File Number:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\My folders\\Deva paul\\AI\\SEM 5\\356 NLP\\NLP Project\\New folder\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 551, in extract_toc\n",
      "    pages = weak_search(toc, pages_search_by_title, tmp_file)\n",
      "TypeError: weak_search() missing 1 required positional argument: 'start_pos'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\My folders\\Deva paul\\AI\\SEM 5\\356 NLP\\NLP Project\\New folder\\1_Annotated_Dataset_Prep\\extract_toc.py\", line 553, in extract_toc\n",
      "    if abs(start_pos - pages[0]) > 100:\n",
      "IndexError: list index out of range\n"
     ]
    }
   ],
   "source": [
    "test_file_toc_loc, test_file_toc_len = extract_toc(test_dir, annual_reports_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(out_dir_path)\n",
    "\n",
    "with open(os.path.join(out_dir_path, out_toc_pos_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(test_file_toc_loc, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open(os.path.join(out_dir_path, out_toc_len_file_name), 'wb') as out_pickle_file:\n",
    "    pickle.dump(test_file_toc_len, out_pickle_file, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_toc_loc.pkl  loaded\n",
      "test_toc_len.pkl  loaded\n",
      "Total sections to be processed:  13213\n",
      "Building dataframe\n",
      "processing file num  0\n",
      "processing file num  300\n",
      "Annotated dataset shape (13213, 4)\n"
     ]
    }
   ],
   "source": [
    "toc_annotated_df = at.annotate_toc_for_test(test_dir, os.path.join(test_dir, out), out_toc_pos_file_name, out_toc_len_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc_annotated_df.to_csv(os.path.join(out_dir_path, out_annotated_file_name), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
