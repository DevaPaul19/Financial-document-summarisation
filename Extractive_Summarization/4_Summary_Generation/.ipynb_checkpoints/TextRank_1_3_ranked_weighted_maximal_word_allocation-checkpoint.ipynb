{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a5a4a8",
   "metadata": {},
   "source": [
    "### Section bodies combined by score order top 1000 words\n",
    "\n",
    "#### Steps:\n",
    "\n",
    "1. Get the sections which have the scores greater than cutoff 0.744291\n",
    "2. Extract the body of sections\n",
    "3. Normalize the scores and adjusted number of words to be picked from the section\n",
    "4. Maximize the word allocation in case some sections doesn't have required word\n",
    "4. Extract top k words\n",
    "5. If no relevant sections -> Write the complete file as summary with top 1000 words\n",
    "6. Compare the system summary with each gold summary and get the rouge score. Take average of all gold summaries for the respective file.\n",
    "7. Take average of all the scores for all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb1e8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "from summa.summarizer import summarize\n",
    "from extract_section_body import extract_section_body\n",
    "from rouge_evaluation import get_rouge_scores\n",
    "from maximal_word_allocation import get_number_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86aed7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_DATASET = True\n",
    "TEST_DATASET = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed50bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if VALIDATION_DATASET:\n",
    "    dir_ = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/'\n",
    "    toc_loc_pkl_file_path = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/FNS2023_Datasets/English/validation/out/valid_toc_loc.pkl'\n",
    "    df_predicted_path = 'C:/My folders/Deva paul/AI/SEM 5/356 NLP/NLP Project/New folder/2_Section_Classification/out/validation_df_predicted.pkl'\n",
    "\n",
    "if TEST_DATASET:\n",
    "    dir_ = '../../../Dataset/FNS2022/English/testing/'\n",
    "    toc_loc_pkl_file_path = '../../../Dataset/Annotated_Dataset/test_toc_loc.pkl'\n",
    "    df_predicted_path = '../../FNP2022/2_Section_Classification/out/test_df_predicted.pkl'\n",
    "\n",
    "annual_reports_dir = \"annual_reports\"\n",
    "gold_summary_dir = \"gold_summaries\"\n",
    "system_summary_dir = 'ranked_weighted_maximal_word_allocation'\n",
    "team_name = 'IT-356'\n",
    "dir_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77ae5bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>toc_section</th>\n",
       "      <th>toc_section_pos</th>\n",
       "      <th>toc_section_len</th>\n",
       "      <th>is_section_in_summary</th>\n",
       "      <th>toc_section_cleaned</th>\n",
       "      <th>pred</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30777</td>\n",
       "      <td>Financial and operational highlights</td>\n",
       "      <td>161</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>financi oper highlight</td>\n",
       "      <td>1</td>\n",
       "      <td>0.407563</td>\n",
       "      <td>0.592437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30777</td>\n",
       "      <td>Strategic report</td>\n",
       "      <td>183</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>strateg report</td>\n",
       "      <td>0</td>\n",
       "      <td>0.932972</td>\n",
       "      <td>0.067028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30777</td>\n",
       "      <td>Global network</td>\n",
       "      <td>189</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>global network</td>\n",
       "      <td>0</td>\n",
       "      <td>0.756613</td>\n",
       "      <td>0.243387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30777</td>\n",
       "      <td>Chairman’s statement</td>\n",
       "      <td>200</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>chairman statement</td>\n",
       "      <td>1</td>\n",
       "      <td>0.018573</td>\n",
       "      <td>0.981427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30777</td>\n",
       "      <td>Chief Executive’s review</td>\n",
       "      <td>204</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>chief execut review</td>\n",
       "      <td>1</td>\n",
       "      <td>0.007140</td>\n",
       "      <td>0.992860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10547</th>\n",
       "      <td>4162</td>\n",
       "      <td>to 110,</td>\n",
       "      <td>21914</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.983343</td>\n",
       "      <td>0.016657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10548</th>\n",
       "      <td>4162</td>\n",
       "      <td>and 117</td>\n",
       "      <td>23018</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.985658</td>\n",
       "      <td>0.014342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10549</th>\n",
       "      <td>4162</td>\n",
       "      <td>to 116</td>\n",
       "      <td>24122</td>\n",
       "      <td>1104</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.987655</td>\n",
       "      <td>0.012345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>4162</td>\n",
       "      <td>to 122</td>\n",
       "      <td>25226</td>\n",
       "      <td>5440</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.987178</td>\n",
       "      <td>0.012822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10551</th>\n",
       "      <td>4162</td>\n",
       "      <td>to 135</td>\n",
       "      <td>30666</td>\n",
       "      <td>5440</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.993895</td>\n",
       "      <td>0.006105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10552 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       file_id                           toc_section  toc_section_pos  \\\n",
       "0        30777  Financial and operational highlights              161   \n",
       "1        30777                      Strategic report              183   \n",
       "2        30777                        Global network              189   \n",
       "3        30777                  Chairman’s statement              200   \n",
       "4        30777              Chief Executive’s review              204   \n",
       "...        ...                                   ...              ...   \n",
       "10547     4162                               to 110,            21914   \n",
       "10548     4162                               and 117            23018   \n",
       "10549     4162                                to 116            24122   \n",
       "10550     4162                                to 122            25226   \n",
       "10551     4162                                to 135            30666   \n",
       "\n",
       "       toc_section_len  is_section_in_summary     toc_section_cleaned  pred  \\\n",
       "0                   22                      0  financi oper highlight     1   \n",
       "1                    6                      1          strateg report     0   \n",
       "2                   11                      0          global network     0   \n",
       "3                    4                      1      chairman statement     1   \n",
       "4                    4                      1     chief execut review     1   \n",
       "...                ...                    ...                     ...   ...   \n",
       "10547             1104                      0                             0   \n",
       "10548             1104                      0                             0   \n",
       "10549             1104                      0                             0   \n",
       "10550             5440                      0                             0   \n",
       "10551             5440                      0                             0   \n",
       "\n",
       "          False      True  \n",
       "0      0.407563  0.592437  \n",
       "1      0.932972  0.067028  \n",
       "2      0.756613  0.243387  \n",
       "3      0.018573  0.981427  \n",
       "4      0.007140  0.992860  \n",
       "...         ...       ...  \n",
       "10547  0.983343  0.016657  \n",
       "10548  0.985658  0.014342  \n",
       "10549  0.987655  0.012345  \n",
       "10550  0.987178  0.012822  \n",
       "10551  0.993895  0.006105  \n",
       "\n",
       "[10552 rows x 9 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted = pickle.load(open(df_predicted_path, 'rb'))\n",
    "df_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32233535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_sections_with_score(file_id):\n",
    "    cutoff_score = 0.744291\n",
    "    df_dict = df_predicted[df_predicted.file_id == int(file_id)][['toc_section', 'True']].to_dict('list')\n",
    "    section_score_dict = {}\n",
    "    toc_sections = df_dict['toc_section']\n",
    "    section_scores = df_dict['True']\n",
    "    for i in range(len(toc_sections)):\n",
    "        if section_scores[i] >= cutoff_score:\n",
    "            section_score_dict[toc_sections[i]] = section_scores[i]\n",
    "    return section_score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b9eeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant_sections_with_body_len(file_id):\n",
    "    section_body_len_dict = {}\n",
    "    section_score_dict = get_relevant_sections_with_score(file_id)\n",
    "    for section in section_score_dict.keys():\n",
    "        body = extract_section_body(file_id, section, dir_, annual_reports_dir, toc_loc_pkl_file_path)\n",
    "        section_body_len_dict[section] = len(body.split(' '))\n",
    "    return section_body_len_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795b782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_section_number_of_words(file_id):\n",
    "    section_num_words_dict = {}\n",
    "    section_score_dict = get_relevant_sections_with_score(file_id)\n",
    "    sections = list(section_score_dict.keys())\n",
    "    section_scores = np.array(list(section_score_dict.values()))\n",
    "    section_body_len_dict = get_relevant_sections_with_body_len(file_id)\n",
    "    section_body_len = np.array(list(section_body_len_dict.values()))\n",
    "    prev_num_required_words = np.zeros(len(section_body_len))\n",
    "    num_words = get_number_of_words(section_scores, section_body_len, 1000, prev_num_required_words)\n",
    "    for i in range(len(sections)):\n",
    "        section_num_words_dict[sections[i]] = int(num_words[i])\n",
    "    return section_num_words_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ee92d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_file = 0\n",
    "os.makedirs(system_summary_dir)\n",
    "for file in os.listdir(os.path.join(dir_, annual_reports_dir)):\n",
    "    try:\n",
    "        #print(\"Processing File Number: \", num_file)\n",
    "        num_file = num_file +1 \n",
    "        file_id = file.split('.')[0]\n",
    "        relevant_sections_with_score = get_relevant_sections_with_score(file_id)\n",
    "        # Section order is maintained\n",
    "        relevant_sections = list(relevant_sections_with_score.keys())\n",
    "        section_num_words_dict = get_section_number_of_words(file_id)\n",
    "        \n",
    "        #print(file_id, relevant_sections)\n",
    "        summary = \"\"\n",
    "        total_number_of_words_in_body = 0\n",
    "        total_number_of_words_in_summary = 0\n",
    "        if relevant_sections:\n",
    "            \n",
    "            #print('Relevant Section Found in ', file_id)\n",
    "            for section in relevant_sections:\n",
    "                number_of_words_to_be_extracted = section_num_words_dict[section]\n",
    "                section_body = extract_section_body(file_id, section, dir_, annual_reports_dir, toc_loc_pkl_file_path)\n",
    "                section_body_split = section_body.split(' ')\n",
    "                number_of_words_in_body = len(section_body_split)\n",
    "                total_number_of_words_in_body = total_number_of_words_in_body + number_of_words_in_body\n",
    "                \n",
    "                if number_of_words_in_body > number_of_words_to_be_extracted:\n",
    "                    summary = summary+ \" \"+\" \".join(section_body_split[:number_of_words_to_be_extracted])\n",
    "                    total_number_of_words_in_summary = total_number_of_words_in_summary + number_of_words_to_be_extracted\n",
    "                else:\n",
    "                    #print(file_id, section, number_of_words_in_body, number_of_words_to_be_extracted)\n",
    "                    summary = summary+ \" \"+\" \".join(section_body_split[:number_of_words_in_body])\n",
    "                    total_number_of_words_in_summary = total_number_of_words_in_summary + number_of_words_in_body\n",
    "                \n",
    "            \n",
    "            #print(file_id, 'number_of_words_in_output_summary' , total_number_of_words_in_summary)    \n",
    "            #print(file_id,  'number_of_words_in_body', total_number_of_words_in_body)\n",
    "            #print('\\n')\n",
    "        else:\n",
    "            #print('Relevant Section Not Found in ', file_id)\n",
    "            summary = open(os.path.join(dir_, annual_reports_dir, file), \"r\", encoding=\"utf-8\").read()\n",
    "            summary_split = summary.split(' ')\n",
    "            number_of_words = len(summary_split)\n",
    "            #print(number_of_words)\n",
    "            if number_of_words > 1000:\n",
    "                summary = \" \".join(summary_split[:1000])\n",
    "        \n",
    "        with open(os.path.join(system_summary_dir, file_id+'_'+team_name+'.txt'), 'w', encoding='utf-8') as f:\n",
    "            f.write(str(summary))\n",
    "            \n",
    "        if \".DS_Store\" in file:\n",
    "            continue\n",
    "    except Exception as e:\n",
    "        print(file, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e297d691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing File Number:  0\n",
      "Processing File Number:  50\n",
      "Processing File Number:  100\n",
      "Processing File Number:  150\n",
      "Processing File Number:  200\n",
      "Processing File Number:  250\n",
      "Processing File Number:  300\n",
      "Processing File Number:  350\n",
      "Processing File Number:  400\n",
      "Number of files processed:  413\n"
     ]
    }
   ],
   "source": [
    "if VALIDATION_DATASET:\n",
    "    gold_summary_dir_ =  os.path.join(dir_, gold_summary_dir)\n",
    "    rouge_scores = get_rouge_scores(system_summary_dir, gold_summary_dir_)\n",
    "    rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d632c3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'p': 0.5287483372955228,\n",
       "  'r': 0.526186998465489,\n",
       "  'f': 0.4484482223138018},\n",
       " 'rouge-2': {'p': 0.33079345760910256,\n",
       "  'r': 0.35674092294433196,\n",
       "  'f': 0.29049689103169846}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683af247",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
